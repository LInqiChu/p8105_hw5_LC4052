---
title: "p8105_hw5_LC4052"
output: github_document
date: "2025-11-05"
---

```{r}
library(tidyverse)
library(rvest)
library(broom)
library(dplyr)
library(ggplot2)
library(knitr)
```

# Problem 1

## Write a function

```{r}
bday_sim = function(n_room){
  
  birthdays = sample(1:365, n_room, replace = TRUE)
  
  repeated_bday = length(unique(birthdays)) < n_room
  
  repeated_bday

}

```

## Simulation

```{r}
bday_sim_results = 
  expand_grid(
    bdays = 2:50,
    iter = 1:10000
  ) |>
  mutate(
    result = map_lgl(bdays, bday_sim)
  ) |>
  group_by(
    bdays
  ) |>
  summarize(
    prob_repeat = mean(result)
  )

```

## Make a plot

```{r}
bday_sim_results |>
  ggplot(aes(x = bdays, y = prob_repeat)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Birthday Simulation Results",
    subtitle = "Probability of at least two people sharing a birthday vs. group size",
    x = "Group Size (number of people)",
    y = "Probability",
    caption = "Based on 10,000 simulations per group size"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  ) 

```
When group size is 23, the probability that at least two people share a birthday is approximately 50%. When group size is 50, the probability approaches 100%.


# Problem 2

```{r}
# Write the function
sim_mean_sd = function(n = 30, mu = 0, sigma = 5) {
  
  x = rnorm(n, mean = mu, sd = sigma)
  
  tidy_result = broom::tidy(t.test(x, mu = 0))
  
  tibble(
    mu_hat = tidy_result$estimate,
    p_value = tidy_result$p.value,
    reject = tidy_result$p.value < 0.05 
    )
}

```

```{r}
mu_values = c(0, 1, 2, 3, 4, 5, 6)
set.seed(1)

# Simulation
sim_results = 
  tibble(mu = mu_values) |>
  mutate(
    output = map(mu, ~map_df(1:5000, function(i) sim_mean_sd(mu = .x)))
  ) |>
  unnest(output)

```

```{r}
# Calculate the power
power_results = 
  sim_results |>
  group_by(mu) |>
  summarize(
    power = mean(reject)
  )

power_results

```

```{r}
# Draw power plot
power_plot = 
  power_results |>
  ggplot(aes(x = mu, y = power)) +
  geom_point(size = 3) +
  geom_line() +
  labs(
    title = "Power Analysis: Effect Size vs. Power",
    x = "True value of μ (effect size)",
    y = "Power (Proportion of rejections)",
    caption = "n = 30, σ = 5, α = 0.05, 5000 simulations per μ"
  ) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.1)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

power_plot

```
When μ = 0 (null hypothesis is true), the power is approximately 0.05, which equals the Type I error rate α. As the true effect size increases, power increases. The power approaches 1.0 for μ ≥ 4. This indicates that larger effect sizes are substantially easier to detect with statistical tests.


```{r}
# Calculate the two means
mu_hat_summary = 
  sim_results |>
  group_by(mu) |>
  summarize(
    avg_mu_hat_all = mean(mu_hat), 
    avg_mu_hat_rejected = mean(mu_hat[reject])
  )

mu_hat_summary
```

```{r}
# Draw Plot
mu_hat_long = 
  mu_hat_summary |>
  pivot_longer(
    cols = c(avg_mu_hat_all, avg_mu_hat_rejected),
    names_to = "sample_type",
    values_to = "avg_mu_hat"
  ) |>
  mutate(
    sample_type = recode(sample_type,
                        "avg_mu_hat_all" = "All samples",
                        "avg_mu_hat_rejected" = "Rejected samples only")
  )

overlay_plot = 
  mu_hat_long |>
  ggplot(aes(x = mu, y = avg_mu_hat, color = sample_type)) +
  geom_point(size = 3) +
  geom_line(linewidth = 1) +
  labs(
    title = "Comparison of Average μ_hat Estimates",
    x = "True value of μ",
    y = "Average estimate μ_hat",
    color = "Sample Type"
  ) +
  scale_color_manual(values = c("All samples" = "blue", 
                                 "Rejected samples only" = "red")) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  ) +
  theme(legend.position = "bottom")


overlay_plot

```
The sample average of μ_hat for rejected tests is not approximately equal to the true μ for small effect sizes. This is because when μ is small, we only reject when the sample mean happens to be larger than usual, which creates selection bias. When μ is large, nearly all samples are included in the rejected group, selection bias diminishes.


## Problem 3

```{r}
# Import data
homicide_data = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```
The data has `r nrow(homicide_data)` observations and `r ncol(homicide_data)` variables.

Variables include `r summary(homicide_data)`.

```{r}
# Create city_state variable
homicide_summary = 
  homicide_data |>
  mutate(city_state = str_c(city, ", ", state))

homicide_summary
```

```{r}
# Summary
homicide_comparison = 
  homicide_summary |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )

homicide_comparison 
```

```{r}
# Study the city of Baltimore, MD
baltimore_data = 
  homicide_summary |>
  filter(city_state == "Baltimore, MD")

baltimore_summary = 
  baltimore_data |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )
```

```{r}
# Do the proportion test
baltimore_prop_test = prop.test(
  x = baltimore_summary$unsolved_homicides,
  n = baltimore_summary$total_homicides
)

baltimore_tidy = broom::tidy(baltimore_prop_test)

# Pull the estimated proportion and CI
estimate_table =
  tibble(
  est_prop = baltimore_tidy |> pull(estimate),
  `95% CI Lower` = baltimore_tidy |> pull(conf.low),
  `95% CI Upper` = baltimore_tidy |> pull(conf.high)
)

kable(estimate_table, caption = "Baltimore Homicide Rate Estimate with 95% CI")
```

```{r}
# Do the prop test for each cities
city_prop = 
  homicide_comparison |>
  mutate(
    prop_test_result = 
      purrr::map2(unsolved_homicides, total_homicides, 
                            ~prop.test(x = .x, n = .y))
  ) |>
  mutate(
    tidy_result = purrr::map(prop_test_result, broom::tidy)
  ) |>
  unnest(tidy_result) |>
  select(city_state, total_homicides, unsolved_homicides, 
         estimate, conf.low, conf.high)

city_prop
```

```{r}
# Draw a plot
city_plot = 
  city_prop |>
  mutate(city_state = fct_reorder(city_state, estimate)) |>
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(size = 2, color = "steelblue") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), 
                width = 0.2,
                color = "grey",
                linewidth = 0.5) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    subtitle = "With 95% Confidence Intervals",
    x = NULL,
    y = "Proportion of Unsolved Homicides"
  ) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5)
  )

city_plot
```